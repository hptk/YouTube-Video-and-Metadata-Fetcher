\section{Fetching an unbiased set of video IDs}
For video analysis, an unbiased set of sample videos might be a requirement or
a desire for the analyst. YouTube, of course, is inherently relying on its
ability to provide the users the videos they want, and in turn this leads to
biased samples if one was to simply add the videos one found while
browsing YouTube to a list. To circumvent YouTube's attempts at tailoring a set
of videos, the algorithm uses the API to get videos.

\subsection{The YouTube API}
YouTube provides a REST API, from now on referred to as "the API", which can be
queried for information with a set of parameters. The API consists of different
endpoints, and the one used for searching videos is called "search.list". This
endpoint returns a result as a JSON object. This endpoint provides a rich list
of customizable paramaeters, and optimizing the use of these is important to
achieve high efficiency while using the API. 

For a given query, the search.list response will contain at most 50 videos. There
may be multiple pages, as indicated by a \texttt{nextPageToken} in the JSON
object, but no more than ten pages are returned for any one set of parameters.
To get a complete list of video IDs for a given set of parameters the chosen
query has to be split up into subqueries that by themselves does not match more
than 500 videos. This splitting, and how we recommend doing it, is discussed in
detail in this section.

The main problem with
the 500 video limit for a static parameter set is that it can not be a good
sample. There might be a lot of other videos which match the requested
parameter, but subsequent requests to the API only return more or less the exact
same sample. There are minor variations in the returned sample, and we will 
discuss this and the related issues in more detail later. 

As a side note it should be mentioned that using an actual web crawler will have
properties an API reliant fetcher can not recreate. A crawler will have its 
behaviour logged by YouTube, which in turn provides more content in line with
what it thinks the crawler likes. The resulting set of videos will be more like
a set of videos a given user is likely to see, it is inherently biased. For some
cases such a set of videos might be desirable, for instance if one wants to
focus on popular videos, or if one wants to measure how biased a set becomes
over time.

Before continuing a few terms will have to be clarified. A  "static parameter 
set" is the set of parameters that are static, globally, for a set of queries, 
like "All videos which are related to the word 'fun', that are 2D and have a 
high video quality". A "variable parameter" is a parameter that can be changed 
for every single request in a request chain, while the static parameter set 
remains untouched. This results in the ability to create many different
variations of the "static parameter set" in order to exceed the 500 videos 
maximum.

From the search.list API endpoint only four different variables can be varied 
between requests in a chain. All other parameters are in some kind static and
would result in a maximum of 500 videos. Following is a description of the
variable parameters.

\subsubsection{location and locationRadius}
The problem with this parameter is that not every video on YouTube has specified
the location in the metadata. Evaluating some hundred thousands of videos
metadata has shown that only 5-10\% of the videos has specified a location in
their metadata. We can not verify that this is the average on all videos
uploaded on YouTube, but just the fact that some (a lot) of videos lack data in
this field indicates that trying to vary it to get an unbiased sample will
result in a set of videos that be default leaves out a lot of videos. For
unbiasedness this is sub-optimal, but not disastrous. It is reasonable to
assume that the set of videos with location data contains a well distributed
and unbiased subset, but this can not easily be verified.

\subsubsection{channelId}
In order to use this parameter as a means of getting an unbiased set of videos,
we would need to have a list of all channels available on YouTube. This is as
difficult as getting all videos of YouTube and therefore varying this parameter 
is probably not a good approach to get an unbiased set of videos. Some channels
also have some thousands of videos uploaded, so with a static parameter set and
only varying the channelId, the API response would be limited to 500 videos. One
could argue that 500 videos is a representative set of videos for a channel, but
the problem is that this subset of the channel's full video list is provided by
YouTube, outside our control. Thus the returned sample can not safely be assumed
to be representative.

\subsubsection{q - search term}
In theory this parameter could be varied and cycled through all possible
combinations of symbols (words, in a wide sense), and through that get an
unbiased set of videos. This is not only unfeasible due to the remarkably big
list of words one would need\footnote{171\,000 words in english alone, then add
all other languages, not to mention names and other word-constructs}, but for
some cases the API quota cost would be extremely high measured as cost per
result. For instance, if one was to get an unbiased set of 3D videos, one would
have to cycle through the whole word list and end up spending quota points on queries
that return stale results. In addition to this, if one is to vary the
search term, the user is left without the ability to manually narrow the result
set. We want to allow the user the ability to create sets of data tailored to
specific tasks, should it be required.

\subsubsection{publishedAfter and publishedBefore}
By having a date range as the varying parameter for a search query, and assuming
that the API actually returns all videos matching the query, the resulting set
would be unbiased with regards to all aspects except from time. Of course, for
a big timeframe there exists more than 500 videos, so to circumvent this cap,
the timeframe can be recursively sliced up until it is so small that less than
500 videos match the parameters. Varying this way leaves the rest of the
parameters unchanged, and the resulting set becomes as much as possible
unbiased.

By slicing the timeframe up like this, one will also be able to get more than
500 videos from a given channel, or from within a geographic zone. It becomes
apparent that varying this parameter alone is the best way to achieve a unbiased
set of videos. A nice bonus is that it also allows customization of the query
without leaving videos out of the resulting set.

\subsubsection{Evaluation / experimental results}
Contrary to natural intuition, the API may return a wholly different set of
videos for two queries one might have thought to return the same as a single
\textit{superquery}. By example: If you search for "All videos between date
$X$ and date $Y$ you might get 1\,000 results. But if you split the query into
two queries: one specifically for 2D videos and one specifically for 3D videos;
you might get a subset of the results for the single query, but in addition,
the API might return a much larger set than before.

By splitting the set timeframe in two, creating two subqueries in the process,
one can trick\footnote{To a certain extent. Our tool is by no means perfect. The
API still severely limits our search.} the API into returning more videos for a given
timeframe than the original query would have yielded. We have expanded our
possible result space simply by using unused parameters to create distinct
subqueries with increasing granularity.
Our tool will do this through narrowing the timeframe of the query (and
in the process providing a section on this on the result page), but
it would be fairly trivial to implement an algorithm that uses all possible
unused parameters and some clever pruning to increase the possible result space.

